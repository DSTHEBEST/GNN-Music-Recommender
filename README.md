# ğŸ§ Graph-Based Music Intelligence Player

<div align="center">

**A graph-powered music recommendation system using Graph Neural Networks (GraphSAGE) for intelligent song discovery**

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Geometric-red.svg)](https://pytorch-geometric.readthedocs.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28-FF4B4B.svg)](https://streamlit.io/)

</div>

---

## ğŸ“– Overview

This project demonstrates an **end-to-end ML system** that models song similarity using graph neural networks. Unlike traditional collaborative filtering, songs are represented as nodes in an audio-similarity graph, enabling multi-hop relationship discovery and explainable recommendations.

**System Highlights:**
- ğŸ§  Offline GNN training with GraphSAGE
- âš¡ Real-time inference via FastAPI
- ğŸ¨ Interactive Streamlit frontend
- ğŸ•¸ï¸ Graph-based visualization

---

## âœ¨ Key Features

### ğŸµ **Graph-Based Recommendations**
Songs are modeled as nodes in an audio-similarity graph instead of using traditional collaborative filtering, capturing complex musical relationships.

### ğŸ§  **Graph Neural Network (GraphSAGE)**
Learns low-dimensional song embeddings through multi-hop neighborhood aggregation, understanding songs in the context of their similar neighbors.

### âš¡ **Offline Training, Online Inference**
GNN embeddings are pre-computed offline and served efficiently at runtime, ensuring fast recommendation responses.

### ğŸ•¸ï¸ **Explainable Recommendations**
Interactive graph visualization reveals the "why" behind recommendations, showing the network of similar songs.

### ğŸ–¥ï¸ **Full-Stack ML System**
Complete production-ready architecture:
- **Backend**: FastAPI for high-performance inference
- **Frontend**: Streamlit for interactive UI
- **ML Pipeline**: PyTorch Geometric for graph learning

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spotify-derived Dataset       â”‚
â”‚   (Audio Features + Metadata)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio Feature Normalization    â”‚
â”‚  (StandardScaler)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Song Similarity Graph         â”‚
â”‚   (Cosine Similarity Edges)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GraphSAGE Training            â”‚
â”‚   (Offline, Unsupervised)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Song Embeddings (.npy)        â”‚
â”‚   Cached for Fast Retrieval     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Inference Layer       â”‚
â”‚   (REST API Endpoints)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI                  â”‚
â”‚   + PyVis Graph Visualization   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ•¸ï¸ Graph Modeling

### Graph Structure
- **Nodes**: Individual songs from the dataset
- **Edges**: Audio similarity connections (cosine similarity threshold-based)
- **Edge Weight**: Similarity score between connected songs

### Node Features
Each song is represented by normalized audio features:
- **Danceability**: How suitable a track is for dancing
- **Energy**: Intensity and activity measure
- **Tempo**: Beats per minute (BPM)
- **Valence**: Musical positiveness/happiness

### Graph Construction
Edges are created when similarity exceeds a fixed threshold, producing a **well-connected but non-dense graph** that captures meaningful musical relationships without overwhelming connectivity.

---

## ğŸ§  GNN Model Details

| Parameter | Value |
|-----------|-------|
| **Architecture** | GraphSAGE |
| **Number of Layers** | 2 |
| **Embedding Dimension** | 64 |
| **Training Mode** | Unsupervised |
| **Loss Function** | Embedding norm regularization |
| **Aggregation** | Mean pooling |

The learned embeddings capture **multi-hop similarity patterns** between songs, enabling the model to understand not just direct similarities but also transitive musical relationships.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Machine Learning** | PyTorch, PyTorch Geometric |
| **Backend API** | FastAPI, Uvicorn |
| **Frontend** | Streamlit |
| **Visualization** | PyVis (Interactive Network Graphs) |
| **Data Processing** | Pandas, NumPy, scikit-learn |
| **Data Source** | Spotify-derived audio features |
| **Language** | Python 3.10+ |

---

## ğŸ“ Project Structure

```
music-gnn-player/
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py              # FastAPI application & endpoints
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                   # Streamlit UI application
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ prepare_dataset.py       # Data preprocessing pipeline
â”‚   â”œâ”€â”€ build_graph.py           # Graph construction from audio features
â”‚   â””â”€â”€ train_gnn.py             # GraphSAGE model training
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ spotify_ml.csv           # Dataset (audio features)
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10 or higher
- pip package manager
- Virtual environment (recommended)

### Installation & Setup

#### 1ï¸âƒ£ Clone the repository
```bash
git clone <your-repo-url>
cd music-gnn-player
```

#### 2ï¸âƒ£ Create virtual environment
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

#### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Build the similarity graph
```bash
python ml/build_graph.py
```

#### 5ï¸âƒ£ Train the GNN model
```bash
python ml/train_gnn.py
```

#### 6ï¸âƒ£ Start the backend server
```bash
uvicorn backend.app.main:app --reload
```
The API will be available at `http://localhost:8000`

#### 7ï¸âƒ£ Launch the frontend (in a new terminal)
```bash
streamlit run frontend/app.py
```
The UI will open automatically at `http://localhost:8501`

---

## ğŸ’¡ Design Decisions

### Why Graph-Based?
Graph-based modeling was chosen over traditional matrix factorization to capture **multi-hop relationships** between songs. This allows the system to recommend songs that are similar not just directly, but through transitive musical connections.

### Offline Training Strategy
Offline training ensures **fast and reliable inference**. Embeddings are pre-computed once and served efficiently, making the system production-ready.

### Decoupled Architecture
The system uses a **microservices-inspired architecture** with clear separation between ML pipeline, API layer, and UI. This allows independent scaling and deployment of each component.

### External API Considerations
Spotify API integration is treated as an **optional enrichment layer** rather than a core dependency, ensuring the system works reliably regardless of external API constraints.

---

## ğŸ”® Future Improvements

- [ ] **User-specific personalization graphs** - Incorporate listening history and user preferences
- [ ] **Heterogeneous graphs** - Add artist nodes, genre nodes, and cross-entity relationships
- [ ] **Live Spotify preview integration** - Stream 30-second audio previews directly in UI
- [ ] **Graph Attention Networks (GAT)** - Experiment with attention mechanisms for weighted aggregation
- [ ] **Cloud deployment** - Deploy on AWS/GCP with containerization (Docker + Kubernetes)
- [ ] **A/B testing framework** - Compare GNN recommendations against baseline methods
- [ ] **Real-time learning** - Implement online learning from user interactions

---

## ğŸ‘¤ Author

**Devansh Sharma**  
Machine Learning Enthusiast


---

## â­ Show Your Support

If you find this project interesting or helpful:

- Give it a **â­ star** on GitHub â€” it helps more people discover the project!
- Fork it and build your own version
- Share it with others who might find it useful

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

- Dataset derived from Spotify's audio feature API
- Built with inspiration from graph-based recommendation systems research
- PyTorch Geometric community for excellent documentation

---

<div align="center">

**Made with â¤ï¸ and Graph Neural Networks**

</div>
